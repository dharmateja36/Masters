{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730e3ee1",
   "metadata": {},
   "source": [
    "## Dharma Teja Kolluri - 016190473 - HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84278df",
   "metadata": {},
   "source": [
    "### Chapter 4, Ex-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64223ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0346f4",
   "metadata": {},
   "source": [
    "#### a) Calculate the entropy for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20a78b",
   "metadata": {},
   "source": [
    "Ans: To calculte the entropy, we use following formula: -Σp(x)log p(x). From the above question, Age, Education, Maritial status and Occupation are descriptive features whereas Annual income is target feature. From the above formula, p(x) is the probability of each level such as <25k is 2/8, 25k-50k is 5/8 and >50k is 1/8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9aa77d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the dataset is  1.2988  bits\n"
     ]
    }
   ],
   "source": [
    "Entropy= -((2/8 *np.log2(2/8)) +(5/8*np.log2(5/8)) +(1/8*np.log2(1/8)))\n",
    "print (\"Entropy of the dataset is \",round(Entropy,4),\" bits\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937363dd",
   "metadata": {},
   "source": [
    "#### b) Calculate the Gini index for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11afa3",
   "metadata": {},
   "source": [
    "Ans: Gini Index can be calculated using the following formula: Σp(x) p(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62c5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini index for the dataset is  0.53125\n"
     ]
    }
   ],
   "source": [
    "gini_index = (((2/8)*(6/8))+ ((5/8)*(3/8))+((1/8)*(7/8)))\n",
    "print(\"Gini index for the dataset is \", gini_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1f463",
   "metadata": {},
   "source": [
    "#### c) When building a decision tree, the easiest way to handle a continuous feature is to define a threshold around which splits will be made. What would be the optimal threshold to split the continuous AGE feature (use information gain based on entropy as the feature selection measure)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566e259",
   "metadata": {},
   "source": [
    "Ans: From the above question, to split the data based on AGE feature, it is best to consider threshold as AGE is continous feature. We need to sort the data first based on the age: \n",
    "\n",
    "ID AGE ANNUAL INCOME\n",
    "\n",
    "3  18    25K\n",
    "\n",
    "6  24    25K\n",
    "\n",
    "4  28   25K–50K\n",
    "\n",
    "5  37   25K–50K\n",
    "\n",
    "1  39   25K–50K\n",
    "\n",
    "8  40    50K\n",
    "\n",
    "2  50   25K–50K+\n",
    "\n",
    "7  52   25K–50K\n",
    "\n",
    "We can split the above data into 3 thresholds such as 1) Age (24+28)/2= >26 (2) (40+39)= >39.5 (3) (40-50)= >45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c008df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy Calculation:\n",
      "E1 Entropy=0\n",
      "E2 Entropy = , 0.65 bits\n",
      "E3 Entropy = , 0.971 bits\n",
      "E4 Entropy = , 0.9183 bits\n",
      "E5 Entropy = , 1.4591 bits\n",
      "E6 Entropy=0\n",
      " \n",
      "Remainder Calculation: \n",
      "Remainder of E1 & E2 =  0.4875 bits\n",
      "Remainder of E3 & E4 =  0.9512 bits\n",
      "Remainder of E5 & E6 =  1.0944 bits\n",
      " \n",
      "Information gain Calculation: \n",
      "E1 E2 information gain =  0.8113 bits\n",
      "E3 E4 information gain =  0.3476 bits\n",
      "E5 E6 information gain =  0.2044 bits\n"
     ]
    }
   ],
   "source": [
    "## Entropy of the overall dataset has been calculated in the above question which is 1.2988\n",
    "\n",
    "print(\"Entropy Calculation:\")\n",
    "print(\"E1 Entropy=0\")\n",
    "E2=-((5/6 *np.log2(5/6)) +(1/6*np.log2(1/6)))\n",
    "print(\"E2 Entropy = ,\", round(E2,4), \"bits\")\n",
    "E3=-((2/5 *np.log2(2/5)) +(3/5*np.log2(3/5)))\n",
    "print(\"E3 Entropy = ,\", round(E3,4), \"bits\")\n",
    "E4=-((2/3 *np.log2(2/3)) +(1/3*np.log2(1/3)))\n",
    "print(\"E4 Entropy = ,\", round(E4,4), \"bits\")\n",
    "E5=-((2/6 *np.log2(2/6)) +(3/6*np.log2(3/6))+(1/6 *np.log2(1/6)))\n",
    "print(\"E5 Entropy = ,\", round(E5,4), \"bits\")\n",
    "print(\"E6 Entropy=0\")\n",
    "print(\" \");\n",
    "print(\"Remainder Calculation: \")\n",
    "rem_E1_E2=((6/8)*(E2) + (2/8)*(0))\n",
    "print(\"Remainder of E1 & E2 = \", round(rem_E1_E2,4), \"bits\")\n",
    "rem_E3_E4=((3/8)*(E4) + (5/8)*(E3))\n",
    "print(\"Remainder of E3 & E4 = \", round(rem_E3_E4,4), \"bits\")\n",
    "rem_E5_E6=((2/8)*(0) + (6/8)*(E5))\n",
    "print(\"Remainder of E5 & E6 = \", round(rem_E5_E6,4), \"bits\")\n",
    "print(\" \");\n",
    "print(\"Information gain Calculation: \")\n",
    "info_gain_E1_E2 = 1.2988-rem_E1_E2\n",
    "print(\"E1 E2 information gain = \",round(info_gain_E1_E2,4), \"bits\")\n",
    "info_gain_E3_E4 = 1.2988-rem_E3_E4\n",
    "print(\"E3 E4 information gain = \",round(info_gain_E3_E4,4), \"bits\")\n",
    "info_gain_E5_E6 = 1.2988-rem_E5_E6\n",
    "print(\"E5 E6 information gain = \",round(info_gain_E5_E6,4), \"bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d4fd7",
   "metadata": {},
   "source": [
    "From the above information, we can say that the threshold >26 age has highest information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a96ca",
   "metadata": {},
   "source": [
    "#### d) Calculate information gain (based on entropy) for the EDUCATION, MARITAL STATUS, and OCCUPATION features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "644e3c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy  of Education: \n",
      "Entropy of Bachelor=  0\n",
      "Entropy of HighSchool=  1.0 bits\n",
      "Entropy of Doctrate=  0\n",
      " \n",
      "Entropy  of Marital Status: \n",
      "Entropy of Never_Married=  0.9183  bits\n",
      "Entropy of Married=  0.8113  bits\n",
      "Entropy of Divorced=  0\n",
      " \n",
      "Entropy  of Occupation: \n",
      "Entropy of transport=  0\n",
      "Entropy of Professional=  0.9183  bits\n",
      "Entropy of Agriculture= 1.0  bits\n",
      "Entropy of Armed Force=  0\n",
      " \n",
      "Remainder calculation of EDUCATION, MARITAL STATUS, and OCCUPATION features\n",
      "Remainder of Education=  0.5  bits\n",
      "Remainder of marital status= 0.75  bits\n",
      "Remainder of occupation= 0.5944  bits\n",
      " \n",
      "Information Gain based on Entropy: \n",
      "Information Gain of Education= 0.7988  bits\n",
      "Information Gain of marital status= 0.5488  bits\n",
      "Information Gain of occupation= 0.7044  bits\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy  of Education: \")\n",
    "E_bachelor=0\n",
    "print(\"Entropy of Bachelor= \",E_bachelor)\n",
    "E_highschool=-((2/4 *np.log2(2/4)) +(2/4*np.log2(2/4)))\n",
    "print(\"Entropy of HighSchool= \",round(E_highschool,4), \"bits\")\n",
    "E_doctrate=0\n",
    "print(\"Entropy of Doctrate= \",E_doctrate)\n",
    "print(\" \")\n",
    "print(\"Entropy  of Marital Status: \")\n",
    "E_Never_Married=-((2/3 *np.log2(2/3)) +(1/3*np.log2(1/3)))\n",
    "print(\"Entropy of Never_Married= \" ,round(E_Never_Married,4),\" bits\")\n",
    "E_Married=-((3/4 *np.log2(3/4)) +(1/4*np.log2(1/4)))\n",
    "print(\"Entropy of Married= \" ,round(E_Married,4),\" bits\")\n",
    "E_Divorced=0\n",
    "print(\"Entropy of Divorced= \",E_Divorced)\n",
    "print(\" \")\n",
    "print(\"Entropy  of Occupation: \")\n",
    "E_transport=0\n",
    "print(\"Entropy of transport= \",E_transport)\n",
    "E_Professional=-((2/3 *np.log2(2/3)) +(1/3*np.log2(1/3)))\n",
    "print(\"Entropy of Professional= \" ,round(E_Professional,4),\" bits\")\n",
    "E_Agriculture=-((1/2 *np.log2(1/2)) +(1/2*np.log2(1/2)))\n",
    "print(\"Entropy of Agriculture=\" ,round(E_Agriculture,4),\" bits\")\n",
    "E_ArmedForce=0\n",
    "print(\"Entropy of Armed Force= \",E_ArmedForce)\n",
    "print(\" \")\n",
    "print(\"Remainder calculation of EDUCATION, MARITAL STATUS, and OCCUPATION features\")\n",
    "rem_Edu=((4/8)*(E_highschool) + (3/8)*(E_bachelor)+(1/8)*(E_doctrate))\n",
    "print(\"Remainder of Education= \" ,round(rem_Edu,4),\" bits\")\n",
    "rem_mar_status=((3/8)*(E_Never_Married)+(4/8)*(E_Married)+(1/8)*(E_Divorced))\n",
    "print(\"Remainder of marital status=\" ,round(rem_mar_status,4),\" bits\")\n",
    "rem_occ=((2/8)*(E_transport) + (3/8)*(E_Professional)+(2/8)*(E_Agriculture)+(1/8)*(E_ArmedForce))\n",
    "print(\"Remainder of occupation=\" ,round(rem_occ,4),\" bits\")\n",
    "print(\" \")\n",
    "print(\"Information Gain based on Entropy: \")\n",
    "info_gain_Education = 1.2988-rem_Edu\n",
    "print(\"Information Gain of Education=\" ,round(info_gain_Education,4),\" bits\")\n",
    "info_gain_mar_status = 1.2988-rem_mar_status\n",
    "print(\"Information Gain of marital status=\" ,round(info_gain_mar_status,4),\" bits\")\n",
    "info_gain_occ = 1.2988-rem_occ\n",
    "print(\"Information Gain of occupation=\" ,round(info_gain_occ,4),\" bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73e3b",
   "metadata": {},
   "source": [
    "#### e) Calculate the information gain ratio (based on entropy) for EDUCATION, MARITAL STATUS, and OCCUPATION features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49940b27",
   "metadata": {},
   "source": [
    "Ans: Information Gain ratio can be calculated with following formula: Information gain/Entropy. Since we already have the values of information gain, we have to calculate the entropy for the whole feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6be7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy Calculation for whole features: \n",
      "Entropy for Education = 1.4056   bits\n",
      "Entropy for Marital Status= 1.4056   bits\n",
      "Entropy for Occupation = 1.9056   bits\n",
      " \n",
      "Information Gain Ratio for Education, Marital Status and Occupation features: \n",
      "Information Gain Ratio of Education = 0.5683\n",
      "Information Gain Ratio of Marital Status = 0.3904\n",
      "Information Gain Ratio of Occupation = 0.3696\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy Calculation for whole features: \")\n",
    "E_edu= -((4/8 *np.log2(4/8)) +(3/8*np.log2(3/8)) +(1/8*np.log2(1/8)))\n",
    "print(\"Entropy for Education =\" ,round(E_edu,4),\"  bits\")\n",
    "E_mar_status= -((4/8 *np.log2(4/8)) +(3/8*np.log2(3/8)) +(1/8*np.log2(1/8)))\n",
    "print(\"Entropy for Marital Status=\" ,round(E_mar_status,4),\"  bits\")\n",
    "E_occ= -((2/8 *np.log2(2/8)) +(3/8*np.log2(3/8)) +(1/8*np.log2(1/8))+(2/8*np.log2(2/8)))\n",
    "print(\"Entropy for Occupation =\" ,round(E_occ,4),\"  bits\")\n",
    "print(\" \")\n",
    "print(\"Information Gain Ratio for Education, Marital Status and Occupation features: \")\n",
    "info_gain_ratio_edu=round(info_gain_Education,4)/E_edu\n",
    "print(\"Information Gain Ratio of Education =\" ,round(info_gain_ratio_edu,4))\n",
    "info_gain_ratio_mar_status=round(info_gain_mar_status,4)/E_mar_status\n",
    "print(\"Information Gain Ratio of Marital Status =\" ,round(info_gain_ratio_mar_status,4))\n",
    "info_gain_ratio_occ=round(info_gain_occ,4)/E_occ\n",
    "print(\"Information Gain Ratio of Occupation =\" ,round(info_gain_ratio_occ,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f019827",
   "metadata": {},
   "source": [
    "#### f) Calculate information gain using the Gini index for the EDUCATION, MARITAL STATUS, and OCCUPATION features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87564156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Index of Bachelor=0\n",
      "Gini Index of HighSchool= 0.5   bits\n",
      "Gini Index of Doctrate=0\n",
      "Gini Index of Never_Married= 0.4444   bits\n",
      "Gini Index of Married= 0.375   bits\n",
      "Gini Index of Divorced=0\n",
      "Gini Index of transport=0\n",
      "Gini Index of Professional= 0.4444   bits\n",
      "Gini Index of Agriculture= 0.5   bits\n",
      "Gini Index of Armed Force=0\n",
      " \n",
      "Remainder calculation of each feature: \n",
      "Remainder of Education= 0.25  bits\n",
      "Remainder of marital status= 0.3542  bits\n",
      "Remainder of occupation= 0.2917  bits\n",
      " \n",
      "Information gain using the GINI Index for Education, Maritial Status and Occupation: \n",
      "Information Gain of Education= 0.2812  bits\n",
      "Information Gain of marital status= 0.177  bits\n",
      "Information Gain of occupation= 0.2395  bits\n"
     ]
    }
   ],
   "source": [
    "# We know that the GINI Index for the whole data set is 0.53125. We have to calculate the GINI Index for each feature\n",
    "print(\"Gini Index of Bachelor=0\")\n",
    "GI_highschool= ((2/4)*(2/4) +(2/4) *(2/4))\n",
    "print(\"Gini Index of HighSchool=\" ,round(GI_highschool,4),\"  bits\")\n",
    "print(\"Gini Index of Doctrate=0\")\n",
    "GI_Never_Married=((1/3)*(2/3) +(2/3)*(1/3))\n",
    "print(\"Gini Index of Never_Married=\" ,round(GI_Never_Married,4),\"  bits\")\n",
    "GI_Married=((3/4)*(1/4) +(1/4)*(3/4))\n",
    "print(\"Gini Index of Married=\" ,round(GI_Married,4),\"  bits\")\n",
    "print(\"Gini Index of Divorced=0\")\n",
    "print(\"Gini Index of transport=0\")\n",
    "GI_Professional=((1/3)*(2/3) +(2/3)*(1/3))\n",
    "print(\"Gini Index of Professional=\" ,round(GI_Professional,4),\"  bits\")\n",
    "GI_Agriculture= ((2/4)*(2/4) +(2/4)*(2/4))\n",
    "print(\"Gini Index of Agriculture=\" ,round(GI_Agriculture,4),\"  bits\")\n",
    "print(\"Gini Index of Armed Force=0\")\n",
    "print(\" \")\n",
    "print(\"Remainder calculation of each feature: \")\n",
    "rem_edu=((4/8)*(GI_highschool) + (3/8)*(0)+(1/8)*(0))\n",
    "print(\"Remainder of Education=\" ,round(rem_edu,4),\" bits\")\n",
    "rem_mar_status=((3/8)*(GI_Never_Married)+(4/8)*(GI_Married)+(1/8)*(0))\n",
    "print(\"Remainder of marital status=\" ,round(rem_mar_status,4),\" bits\")\n",
    "rem_occ=((2/8)*(0) + (3/8)*(GI_Professional)+(2/8)*(GI_Agriculture)+(1/8)*(0))\n",
    "print(\"Remainder of occupation=\" ,round(rem_occ,4),\" bits\")\n",
    "print(\" \")\n",
    "print(\"Information gain using the GINI Index for Education, Maritial Status and Occupation: \")\n",
    "info_gain_edu = 0.5312-rem_edu\n",
    "print(\"Information Gain of Education=\" ,round(info_gain_edu,4),\" bits\")\n",
    "info_mar_status = 0.5312-rem_mar_status\n",
    "print(\"Information Gain of marital status=\" ,round(info_mar_status,4),\" bits\")\n",
    "info_gain_occ = 0.5312-rem_occ\n",
    "print(\"Information Gain of occupation=\" ,round(info_gain_occ,4),\" bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e7a00",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2d40e",
   "metadata": {},
   "source": [
    "Pruning is a technique that will eliminate the nodes that doesn't classify the false return values. In short, this technique will provide the right tree for target true cases by eliminating the false cases.\n",
    "\n",
    "In the question, decision tree is given for heart disease prediction task. The target feature is having the heart disease based upon the features Chest Pain and Blood pressure. It is also given that the algorithm is applied in a bottom-up, left-to-right approach.\n",
    "\n",
    "The section of the decision tree located beneath the node corresponding to blood pressure will be the initial focus of the pruning algorithm. The black nodes in the diagram indicate the extent of this subtree. The values enclosed in square brackets indicate the majority class for each node, with the goal level being reached at that particular node. The figures enclosed in round brackets indicate the number of errors produced in the pruning set as a consequence of the predictions made by each node. The topmost node of this branch returns a negative result, leading to no errors in the pruning set. However, the combined number of errors in the two lower-level nodes of this branch is two. Since the number of errors resulting from the leaf nodes is greater than the number of errors resulting from the root node, the algorithm will perform pruning on this subtree.\n",
    "\n",
    "The decision tree model predicts true at the root node, leading to 3 errors on the pruning set. However, each of the leaf nodes produces zero errors. Due to the low error rate in the leaf nodes, the decision tree will not be pruned, despite the higher error rate at the root node. The algorithm has traversed all the non-leaf nodes in the tree, and the decision tree depicted in the image will be the final result returned by the pruning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270fa2bd",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e38eba",
   "metadata": {},
   "source": [
    "#### a) \n",
    "#### Information Gain calculation for Bootstrap Sample A <br>\n",
    "In this Data set, we can observe that the entropy of exercise is 0 as the values in Exercise generate the equal sets. So Remainder value is also 0 for Exercise feature. In Family feature, value 'No' has equal sets which means that the entropy is 0 for that value as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e71877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the Sample A data set for target feature Risk =  0.7219  bits\n",
      "Entropy of the Exercise is  0  bits\n",
      "Remainder of the Exercise =  0  bits\n",
      "Information gain of Exercise = 0.7219\n",
      " \n",
      "Entropy of the Family =  0.9183  bits\n",
      "Remainder of the Family = 0.551  bits\n",
      "Information gain of Family =  0.171\n"
     ]
    }
   ],
   "source": [
    "E_Risk= -((1/5 *np.log2(1/5)) +(4/5*np.log2(4/5)))\n",
    "print(\"Entropy of the Sample A data set for target feature Risk = \",round(E_Risk,4),\" bits\")\n",
    "E_exer=0\n",
    "rem_exer=0\n",
    "print(\"Entropy of the Exercise is \",E_exer, \" bits\")\n",
    "print(\"Remainder of the Exercise = \",rem_exer,\" bits\")\n",
    "info_gain_exer = E_Risk-rem_exer\n",
    "print(\"Information gain of Exercise =\" ,round(info_gain_exer,4))\n",
    "print(\" \")\n",
    "E_family= -((1/3 *np.log2(1/3)) +(2/3*np.log2(2/3)))\n",
    "print(\"Entropy of the Family = \" ,round(E_family,4),\" bits\")\n",
    "rem_family = ((3/5)*(E_family))\n",
    "print(\"Remainder of the Family =\" ,round(rem_family,4),\" bits\")\n",
    "info_gain_family = E_Risk-rem_family\n",
    "print(\"Information gain of Family = \" ,round(info_gain_family,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf13647",
   "metadata": {},
   "source": [
    "As we can see that Information gain of Exercise is 0.7219 which is greater than the information gain of Family. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5092cf2f",
   "metadata": {},
   "source": [
    "#### Information Gain calculation for Bootstrap Sample B <br>\n",
    "In this Data set, we can observe that the entropy of Smoker is 0 as the values in Exercise generate the equal sets. So Remainder value is also 0 for Smoker feature. In Obese feature, value 'true' has equal sets which means that the entropy is 0 for that value as well. So we will calculate entropy of 'False' values from Obese feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b878ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the data set Risk = 0.7219  bits\n",
      "Entropy of the Smoker = 0  bits\n",
      "Entropy of the Smoker = 0  bits\n",
      "Information gain of Smoker = 0.7219\n",
      " \n",
      "Entropy of the Obese = 0.9183  bits\n",
      "Remainder of the Obese = 0.551  bits\n",
      "Information gain of Obese = 0.171\n"
     ]
    }
   ],
   "source": [
    "E_Risk= -((1/5 *np.log2(1/5)) +(4/5*np.log2(4/5)))\n",
    "print(\"Entropy of the data set Risk =\" ,round(E_Risk,4),\" bits\")\n",
    "E_Smoker=0\n",
    "Rem_Smoker=0\n",
    "print(\"Entropy of the Smoker =\" ,E_Smoker,\" bits\")\n",
    "print(f\"Entropy of the Smoker =\" ,Rem_Smoker,\" bits\")\n",
    "info_gain_Smoker = E_Risk-Rem_Smoker\n",
    "print(\"Information gain of Smoker =\" ,round(info_gain_Smoker,4))  \n",
    "print(\" \")\n",
    "E_obese= -((1/3 *np.log2(1/3)) +(2/3*np.log2(2/3)))\n",
    "print(\"Entropy of the Obese =\" ,round(E_obese,4),\" bits\")\n",
    "Rem_obese = ((3/5)*(E_obese))\n",
    "print(\"Remainder of the Obese =\" ,round(Rem_obese,4),\" bits\")\n",
    "info_gain_obese = E_Risk-Rem_obese\n",
    "print(\"Information gain of Obese =\" ,round(info_gain_obese,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7351e",
   "metadata": {},
   "source": [
    "As we can see that Information gain of Smoker is 0.7219 which is greater than the information gain of Obese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea4b76",
   "metadata": {},
   "source": [
    "#### Information gain calculation for Bootstrap Sample C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55f28c",
   "metadata": {},
   "source": [
    "In this data set, we can observe the true values for Obese gives Risk as high which can be termed as Entropy value 0. And for the value of no in Family , the risk is high which is only one set of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd404809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the data set Risk = 0.971  bits\n",
      "Entropy of Obese = 0.9183  bits\n",
      "Remainder of Obese = 0.551  bits\n",
      "Information gain of Obese = 0.42\n",
      "\n",
      "Entropy of the Family = 1.0\n",
      "Remainder of Family = 0.8  bits\n",
      "Information gain of Family = 0.171\n"
     ]
    }
   ],
   "source": [
    "E_Risk= -((2/5 *np.log2(2/5)) +(3/5*np.log2(3/5)))\n",
    "print(\"Entropy of the data set Risk =\" ,round(E_Risk,4),\" bits\")\n",
    "E_obese= -((1/3 *np.log2(1/3)) +(2/3*np.log2(2/3)))\n",
    "print(\"Entropy of Obese =\" ,round(E_obese,4),\" bits\")\n",
    "Rem_obese = ((3/5)*(E_obese))\n",
    "print(\"Remainder of Obese =\" ,round(Rem_obese,4),\" bits\")\n",
    "info_gain_obese = E_Risk-Rem_obese\n",
    "print(\"Information gain of Obese =\" ,round(info_gain_obese,4))\n",
    "print(\"\")\n",
    "E_fam= -((2/4 *np.log2(2/4)) +(2/4*np.log2(2/4)))\n",
    "print(\"Entropy of the Family =\" ,round(E_fam,4))\n",
    "Rem_family = ((4/5)*(E_fam))\n",
    "print(\"Remainder of Family =\" ,round(Rem_family,4),\" bits\")\n",
    "info_gain_family = E_Risk-Rem_family\n",
    "print(\"Information gain of Family =\" ,round(info_gain_family,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f5af5",
   "metadata": {},
   "source": [
    "As we can see that Information gain of Obese is 0.42 which is greater than the information gain of Family."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa882da6",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98081b0e",
   "metadata": {},
   "source": [
    "EXERCISE=rarely, SMOKER=false, OBESE=true, FAMILY=yes\n",
    "\n",
    "From the given data set, \n",
    "If Exercie is 'rarely', Risk is 'High' in both cases.\n",
    "If Smoker is 'false', Risk is 'Low' in both cases.\n",
    "If Obese is 'true', Risk is 'High' in both cases.\n",
    "If Family is 'yes', Risk is 'High' in two cases and 'Low' in one case\n",
    "\n",
    "From the above results, it is highly likely to get the Risk as 'High' for the above values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594ac67",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc20fb3",
   "metadata": {},
   "source": [
    "#### a) Which of the descriptive features will the ID3 decision tree induction algorithm choose as the feature for the root node of the decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8441f",
   "metadata": {},
   "source": [
    "Ans: Root node should be the feature that has highest information gain. So we need to find the highest information gain for the features Obese, Smoker and Drinks Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2718f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy Values:\n",
      "Entropy of Cancer_Risk =  1.0  bits\n",
      "Entropy of Obese for True value =  0.9183  bits\n",
      "Entropy of Obese for False value =  0.9183  bits\n",
      "Entropy of Smoker true value =  0.8113  bits\n",
      "Entropy of Smoker false value =  0  bits\n",
      "Entropy of Alcohol true value =  0.971  bits\n",
      "Entropy of Alcohol false value =  0  bits\n",
      "\n",
      "Remainder values: \n",
      "Remainder of Obese =  0.9183  bits\n",
      "Remainder of smoker =  0.5409  bits\n",
      "Remainder of Drink alcohol =  0.8091  bits\n",
      " \n",
      "Information Gain values:\n",
      "Information Gain of Obese =  0.0817  bits\n",
      "Information Gain of smoker =  0.4591  bits\n",
      "Information Gain of drink alcohol =  0.1909  bits\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy Values:\")\n",
    "E_risk=-((3/6 *np.log2(3/6)) +(3/6*np.log2(3/6)))\n",
    "print(\"Entropy of Cancer_Risk = \",round(E_risk,4),\" bits\")\n",
    "E_obese_true=-((2/3 *np.log2(2/3)) +(1/3*np.log2(1/3)))\n",
    "print(\"Entropy of Obese for True value = \",round(E_obese_true,4),\" bits\")\n",
    "E_obese_false=-((1/3 *np.log2(1/3)) +(2/3*np.log2(2/3)))\n",
    "print(\"Entropy of Obese for False value = \",round(E_obese_false,4),\" bits\")\n",
    "E_smoker_true=-((1/4 *np.log2(1/4)) +(3/4*np.log2(3/4)))\n",
    "print(\"Entropy of Smoker true value = \",round(E_smoker_true,4),\" bits\")\n",
    "E_smoker_false=0\n",
    "print(\"Entropy of Smoker false value = \",round(E_smoker_false,4),\" bits\")\n",
    "E_alco_true=-((2/5 *np.log2(2/5)) +(3/5*np.log2(3/5)))\n",
    "print(\"Entropy of Alcohol true value = \",round(E_alco_true,4),\" bits\")\n",
    "E_alco_false=0\n",
    "print(f\"Entropy of Alcohol false value = \",E_alco_false,\" bits\")\n",
    "print(\"\")\n",
    "print(\"Remainder values: \")\n",
    "rem_obese=((3/6)*(E_obese_true) + (3/6)*(E_obese_false))\n",
    "print(\"Remainder of Obese = \",round(rem_obese,4),\" bits\")\n",
    "rem_smoker=((4/6)*(E_smoker_true)+(2/6)*(E_smoker_false))\n",
    "print(\"Remainder of smoker = \",round(rem_smoker,4),\" bits\")\n",
    "rem_alco=((1/6)*(E_alco_false) + (5/6)*(E_alco_true))\n",
    "print(\"Remainder of Drink alcohol = \",round(rem_alco,4),\" bits\")\n",
    "print(\" \")\n",
    "print(\"Information Gain values:\")\n",
    "info_gain_obese = E_risk-rem_obese\n",
    "print(\"Information Gain of Obese = \",round(info_gain_obese,4),\" bits\")\n",
    "info_gain_smoker = E_risk-rem_smoker\n",
    "print(\"Information Gain of smoker = \",round(info_gain_smoker,4),\" bits\")\n",
    "info_gain_alco = E_risk-rem_alco\n",
    "print(f\"Information Gain of drink alcohol = \",round(info_gain_alco,4),\" bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64121413",
   "metadata": {},
   "source": [
    "From the above Information gain values, we can clearly observe that the information gain value of Smoker feature is the highest and it should be used as root node for the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03735711",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad378814",
   "metadata": {},
   "source": [
    "Ans: Some of the features that can be included in this dataset to indicate the Cancer risk could be as follows: <br>\n",
    "i) Alcohol consumption period such as daily, weekly or occassionally. <br>\n",
    "ii) Regular health check ups like if they are taking any check ups once in a year or in 6 months or none. <br>\n",
    "iii) Physical Exercise could be the potential feature to know the frequency of the the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e86813",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14000900",
   "metadata": {},
   "source": [
    "#### a) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9a0b8",
   "metadata": {},
   "source": [
    "Ans: From the question, we can see that the root node for the tree is AGE. But if the Student feature should to be made as Root node, then the information gain should be greater for Student feature than the AGE feature which is 0.247. That means we have to find out the information gain for AGE and STUDENT feature to find out which is better feature as root node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90cb407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of the datset Buys =  0.9403 bits\n",
      "Entropy of the dataset Student for no value is  0.9852  bits\n",
      "Entropy of the dataset Student for yes value is  0.5917  bits\n",
      "Remainder of Student =  0.7885\n",
      "Information gain of Student =  0.1518\n"
     ]
    }
   ],
   "source": [
    "E_Buys = -((5/14 *np.log2(5/14)) +(9/14*np.log2(9/14)))\n",
    "print(\"Entropy of the datset Buys = \", round(E_Buys,4), \"bits\")\n",
    "E_stud_no = -((4/7*np.log2(4/7))+(3/7*np.log2(3/7)))\n",
    "print(\"Entropy of the dataset Student for no value is \", round(E_stud_no,4),\" bits\")\n",
    "E_stud_yes = -((6/7*np.log2(6/7))+(1/7*np.log2(1/7)))\n",
    "print(\"Entropy of the dataset Student for yes value is \", round(E_stud_yes,4),\" bits\")\n",
    "Rem_student = (7/14*(E_stud_no))+(7/14*(E_stud_yes))\n",
    "print(\"Remainder of Student = \", round(Rem_student,4))\n",
    "info_gain_student = E_Buys-Rem_student\n",
    "print(\"Information gain of Student = \",round(info_gain_student,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9f4361",
   "metadata": {},
   "source": [
    "Since the value of information gain for student is 0.1518 which is less than AGE information gain, it is not advised to replace STUDENT feature as root node for AGE feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095ac90",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a29070",
   "metadata": {},
   "source": [
    "Ans: We cannot consider ID as a descriptive field as it is used only to represent the rows with unique continous numbers. And also it is not useful to calculate the entropy or information gain as each id has each value of target feature. As it is continous value, it is not possible to divide it into threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966445d4",
   "metadata": {},
   "source": [
    "### Coding Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "278493c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#To ignore warnings\n",
    "import graphviz\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a32764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data_iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93832616",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eda7164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d0cea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b82d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Columns of Training data (105, 2)\n",
      "Rows of Target variable 105\n"
     ]
    }
   ],
   "source": [
    "X = data_iris.data[:, 2:]\n",
    "Y = data_iris.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "print(\"Rows, Columns of Training data\",X_train.shape)\n",
    "print(\"Rows of Target variable\", Y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5992e5",
   "metadata": {},
   "source": [
    "### Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd967f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0.75, 'X[1] <= 0.8\\ngini = 0.664\\nsamples = 105\\nvalue = [31, 37, 37]'),\n",
       " Text(0.25, 0.25, 'gini = 0.0\\nsamples = 31\\nvalue = [31, 0, 0]'),\n",
       " Text(0.75, 0.25, 'gini = 0.5\\nsamples = 74\\nvalue = [0, 37, 37]')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Iris_dt = DecisionTreeClassifier(criterion='gini',min_samples_split=1.0,max_depth=2)\n",
    "Iris_dt.fit(X_train, Y_train)\n",
    "Y_pred= Iris_dt.predict(X_test)\n",
    "tree.plot_tree(Iris_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d31026",
   "metadata": {},
   "source": [
    "### Classification and Accuracy Report of Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72747337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.50      1.00      0.67        13\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.71        45\n",
      "   macro avg       0.50      0.67      0.56        45\n",
      "weighted avg       0.57      0.71      0.61        45\n",
      "\n",
      " \n",
      "Accuracy Score:\n",
      "71.11111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(\" \")\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(Y_test,Y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f57511",
   "metadata": {},
   "source": [
    "#### Ensembling techniques are used to improve the accuracy scores of the model. Some of the important techniques are Bagging, Boosting and Stacking. We can see each of the technique and their accuracy rates in the below code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169afec",
   "metadata": {},
   "source": [
    "#### Bagging with decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1909344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "irs_bag_Classifier = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state=0), n_estimators=3,\n",
    "    max_samples=5, bootstrap=True, random_state=0)\n",
    "irs_bag_Classifier.fit(X_train, Y_train)\n",
    "Y_pred = irs_bag_Classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6108abd",
   "metadata": {},
   "source": [
    "#### Classification and Accuracy Report of Decision Tree classifier with Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8bf7cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.85      0.92        13\n",
      "           2       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      " \n",
      "Accuracy Score:\n",
      "95.55555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(\" \")\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(Y_test,Y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ed862",
   "metadata": {},
   "source": [
    "From the above Bagging classification, we can see that the accuracy score is 95 which is higher than the Decision Tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da14f4",
   "metadata": {},
   "source": [
    "#### Ensembling Boosting techniques using Ada Classifier, Gradient Boosting and XG Boosting classsifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b72ac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier:\n",
      "Classification report for AdaBoost Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      " \n",
      "Accuracy Score for AdaBoost Classifier:\n",
      "100.0\n",
      " \n",
      "Gradient Boost Classifier:\n",
      "Classification report of Gradient Boosting Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      " \n",
      "Accuracy Score for Gradient Boosting Classifier:\n",
      "100.0\n",
      " \n",
      "XG Boost Classifier: \n",
      "Classification report for XG Boost Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      " \n",
      "Accuracy Score for XG Boost Classifier:\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "Ada_classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=3,learning_rate=0.5)\n",
    "Ada_classifier.fit(X_train, Y_train)\n",
    "Y_pred_ada = Ada_classifier.predict(X_test)\n",
    "print(\"AdaBoost Classifier:\")\n",
    "print(\"Classification report for AdaBoost Classifier:\")\n",
    "print(classification_report(Y_test,Y_pred_ada))\n",
    "print(\" \")\n",
    "print(\"Accuracy Score for AdaBoost Classifier:\")\n",
    "print(accuracy_score(Y_test,Y_pred_ada)*100)\n",
    "print(\" \")\n",
    "GB_classifier = GradientBoostingClassifier(n_estimators=3, learning_rate = 0.5, max_features=2, max_depth = 2, random_state = 0)\n",
    "GB_classifier.fit(X_train, Y_train)\n",
    "Y_pred_gb = GB_classifier.predict(X_test)\n",
    "print(\"Gradient Boost Classifier:\")\n",
    "print(\"Classification report of Gradient Boosting Classifier:\")\n",
    "print(classification_report(Y_test,Y_pred_gb))\n",
    "print(\" \")\n",
    "print(\"Accuracy Score for Gradient Boosting Classifier:\")\n",
    "print(accuracy_score(Y_test,Y_pred_gb)*100)\n",
    "print(\" \")\n",
    "XGB_classifier = XGBClassifier(n_estimators=3, learning_rate = 0.5, max_depth = 2, random_state = 0)\n",
    "XGB_classifier.fit(X_train, Y_train)\n",
    "Y_pred_xgb = XGB_classifier.predict(X_test)\n",
    "print(\"XG Boost Classifier: \")\n",
    "print(\"Classification report for XG Boost Classifier:\")\n",
    "print(classification_report(Y_test,Y_pred_xgb))\n",
    "print(\" \")\n",
    "print(\"Accuracy Score for XG Boost Classifier:\")\n",
    "print(accuracy_score(Y_test,Y_pred_xgb)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1656cf2",
   "metadata": {},
   "source": [
    "From the above accuracy scores from various boosting classifiers, we can say that ensembling helps in improvement of accuracy scores in which all these cases have 100 accuracy rate which is quite high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9be2f4",
   "metadata": {},
   "source": [
    "### Ensembling Stacking Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e6e5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier using the models Random Forest, XG Boost Classifier and Logistic regression: \n",
      "Classification report for Stacking Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      " \n",
      "Accuracy Score for Stacking Classifier:\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "rf_classifier= RandomForestClassifier(n_estimators=3,random_state=0)\n",
    "XGB_classifier = XGBClassifier(n_estimators=3, learning_rate = 0.5, max_depth = 2, random_state = 0)\n",
    "log_reg_classifier = LogisticRegression(random_state=0)\n",
    "estimator = [\n",
    "     ('rf', rf_classifier),\n",
    "     ('xgb', XGB_classifier),\n",
    "     ('lg_reg', log_reg_classifier)\n",
    "]\n",
    "stacking_classifier = StackingClassifier(estimators=estimator)\n",
    "stacking_classifier.fit(X_train, Y_train)\n",
    "Y_pred_stacking = stacking_classifier.predict(X_test)\n",
    "print(\"Stacking Classifier using the models Random Forest, XG Boost Classifier and Logistic regression: \")\n",
    "print(\"Classification report for Stacking Classifier:\")\n",
    "print(classification_report(Y_test,Y_pred_stacking))\n",
    "print(\" \")\n",
    "print(\"Accuracy Score for Stacking Classifier:\")\n",
    "print(accuracy_score(Y_test,Y_pred_stacking)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4596d00",
   "metadata": {},
   "source": [
    "From the above values, we can see that the accuracy value is coming as 100 using Stacking ensembling technique as we have already seen that XB Boost is having the 100% accuracy which could be the same that has been depicted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e588476d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
